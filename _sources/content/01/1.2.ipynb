{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e1c17ac",
   "metadata": {},
   "source": [
    "# 1.2 Gathering and Collecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057102ed",
   "metadata": {},
   "source": [
    "Data collection and gathering is a key component of the data science pipeline. Based on the principle of garbage-in garbage-out, this step might probably have the most relevance out of all. Data collection can be in various way ranging from a social non-profit conducting a survey in the neighborhood by interveiwing people of a specific income group, a cellular network like Verizon taking in real-time call logs from its millions of users or an online retailer tracking their customer's demographics and purchases to have better targeted ads. Data, therefore, can be collected with varying volumes, flow and variety. \n",
    "\n",
    "A critical element in this step is to decide what data to collect and with what flow and granurality. Is it fine to get real-time aggregate data and process it immediately for taking time-sensitive decision or can we store all the incoming data for every single user in a large data dump and process it at our convenience. Decisions like these have an impact on the results we get and this brings us back to the importance of contextual knowledge regarding the business.\n",
    "\n",
    "For the purpose of making data-driven decisions and predictions critical for our organization, attaining a large volume of data covering large variety can have the variation that may help us build better learning models (to be covered up in the next section) and hence make better predictions. If you've ever heard of the term 'Data beats Algorithm' you might soon realize that effective predictions and analysis is not a function of how good the engineering or the learning model is, but is more a function of the quantity, quality and variety of data. There are huge profit making firms with the primary business of offering clean and labeled data. Scale.ai is one such venture that offers clean and labelled vision data that companies can use for computer vision. You might pay a lot to attain that data but it results in effective models for data science.\n",
    "\n",
    "Purpose of this section is to put emphasis on: \n",
    "- How data is collected, stored and secured in various sectors\n",
    "- (followed by) a breif overview of the pipeline: mention of data lakes, sql-like databases, structured/unstructured data and costs/feasibility associated with these decisions (again, will use comprehensive terms)\n",
    "- how to decide what to collect?\n",
    "- **Data beats algorithm. The quality of the model depends on the quality, quantity and variety of data used to build it. (Add Ref) Even a simple model can give great insights without need of adding complexity**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53a037b",
   "metadata": {},
   "source": [
    "### Guided Practice\n",
    "\n",
    "Going back to the Traffic stops case study that we worked on the previous sub-section, we are no going to discuss and evaluate the set of data sources that were collected for this study. We are going to discuss the merits and caveats of each approach and talk about how the integrity of the data can be maintained. Additionally, it will be useful to think about the ideal data set that we might require. We will also circle back on the discussion we previously had about the features and variables we might need for this study.\n",
    "\n",
    "- A number have used census-based estimates of the race distribution of residential populations\n",
    "- This approach has serious limitations that have been recognized by both researchers and the courts\n",
    "- out-of-area drivers and differences in car ownership and travel patterns may result in differences between the residential population and the at-risk population.\n",
    "- Many police agencies now mandate that their officers record official contacts made with citizens during routine traffic or pedestrian stops. These administrative data sources typically include a host of information on characteristics of the stops made by police officers including: the race/ethnicity of the driver or pedestrian; reasons for the stop; and the actions that occurred after the stop, such as searches, contraband found, and citations or arrests made.\n",
    "- Although OPD started collecting stop data voluntarily, it later entered a settlement agreement with the U.S. Justice Department requiring that they collect such data on an ongoing basis\n",
    "- Note that this implicitly excludes freeway stops, because freeways fall under the jurisdiction of the California Highway Patrol.\n",
    "- there is evidence of a substantial nonreporting problem in the data.\n",
    "- as many as 70% of all motor vehicle stops were not reported in the early phases of this study. Court-ordered oversight and increased sanctions for noncompliance raised the number of completed stop forms,\n",
    "- The General Accounting Office (2000) reported that the driverâ€™s race was missing from about 50% of the stops carried out during a racial profiling study in Philadelphia; Smith and Alpert (2002) reported that data were missing for 36% of the stops made in the course of a Richmond, Virginia study;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0f7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5fc3e7e",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Data Collection and working with Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f1d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
