{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb2218f",
   "metadata": {},
   "source": [
    "# Chapter 6: Common Operations in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe309d",
   "metadata": {},
   "source": [
    "Throughout the first 5 chapters, we were able to see the great set of methods and functionalities Pandas offers. It offers you a very flexible and comprehensive toolkit to deal with any dataset in a SQL-like or spreadsheet format. Understanding the functionalities well and being familiar with the fundamentals of Pandas will be extremely resourceful. Being accustomed to pandas will offer you the superpower to do complex analysis and simplify the results in whatever way you may want.\n",
    "\n",
    "Therefore, in order to give you a breif hint of a short set of the limitless capabilities that Pandas can offer, we will go through the guided exercises below. You will cover basic SQL like functions that you can also perform on Pandas. Don't worry if you are not familiar with SQL. Our purpose is to start with combining different tables and appending data to the existing ones. Moreover, we will also have a look at how dataframes can be re-structured into different shapes and multi-indexed structured to get a better view of the dataframe that fulfills the need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ae269d",
   "metadata": {},
   "source": [
    "### Guided Practice\n",
    "\n",
    "In this guided practice we will use additional meta data to help improve the analysis regarding existence of Racial bias in Police stops. In order to move ahead, we will again import the police beat demographic data. Our first task in this exercise would be to combine both the data frames together. But how can we do it when format in both the dataset is very distinct. The police stops data is arranged with a row for every stop, whereas, the demographic data has a row for every beat. \n",
    "\n",
    "Since we need an aggregate analysis for every beat, we will group the police stops data by beat and perform aggregation on for selected columns in each beat. Since this new grouped dataframe will be listed by beat, we will join the demographic dataframe with it in order to compare both stops demographics with racial demographics in each beat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3688feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d3d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the latest police stops dataframe\n",
    "stops_filtered = pd.read_pickle('stops_filtered_2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "157aa1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the beatrace dataframe\n",
    "df = pd.read_pickle('beatrace.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4418888",
   "metadata": {},
   "source": [
    "We will first create a dataframe grouped by beat and we will sum all the dummy variables we created for every race. Remember, applying sum on a dummy variable will give a sum of all True occurences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "186feb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEAT_I</th>\n",
       "      <th>DRRACE_1</th>\n",
       "      <th>DRRACE_2</th>\n",
       "      <th>DRRACE_3</th>\n",
       "      <th>DRRACE_4</th>\n",
       "      <th>DRRACE_5</th>\n",
       "      <th>DRRACE_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111</td>\n",
       "      <td>99.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>64.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>85.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>129.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>35.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>122</td>\n",
       "      <td>65.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>123</td>\n",
       "      <td>139.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>124</td>\n",
       "      <td>103.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>131</td>\n",
       "      <td>114.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>132</td>\n",
       "      <td>49.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEAT_I  DRRACE_1  DRRACE_2  DRRACE_3  DRRACE_4  DRRACE_5  DRRACE_6\n",
       "0     111      99.0     171.0       6.0      78.0      17.0       2.0\n",
       "1     112      64.0     153.0       3.0      44.0       8.0       1.0\n",
       "2     113      85.0     137.0       3.0      64.0      17.0       4.0\n",
       "3     114     129.0     220.0       8.0      95.0      33.0       3.0\n",
       "4     121      35.0      56.0       3.0      23.0       5.0       0.0\n",
       "5     122      65.0      89.0       2.0      39.0      11.0       1.0\n",
       "6     123     139.0     366.0      12.0     123.0      44.0      10.0\n",
       "7     124     103.0     169.0       4.0     137.0      17.0       1.0\n",
       "8     131     114.0     491.0      10.0      85.0      43.0       1.0\n",
       "9     132      49.0     156.0       1.0      45.0      11.0       5.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by Beat and sum all Race dummys\n",
    "stops_race = stops_filtered.groupby('BEAT_I').sum()[['DRRACE_1','DRRACE_2','DRRACE_3',\n",
    "                                                     'DRRACE_4','DRRACE_5','DRRACE_6']]\n",
    "# Reset index will enable us to have the beat id as a column rather than an index\n",
    "stops_race = stops_race.reset_index()\n",
    "stops_race.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48a46a",
   "metadata": {},
   "source": [
    "We will now use sql-like JOIN operations as shown below to merge both the datasets. Pandas offers the [.join()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html) to perform this.\n",
    "![](https://www.dofactory.com/img/sql/sql-joins.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee276083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Kaggle Data\n",
    "#stops_race.join(df, on='Beat_Name', how='left', rsuffix='_kaggle')\n",
    "#stops_race['Beat_Name'] = stops_race['Beat_Name'].str.zfill(4).astype('object')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
